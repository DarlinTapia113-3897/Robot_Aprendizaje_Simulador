# Robot_Aprendizaje_Simulador
Swarm Analyzer Elite es un simulador de enjambres basado en IA con Q-Learning. Los agentes inteligentes con habilidades Ãºnicas (velocidad, memoria, exploraciÃ³n) aprenden en tiempo real a resolver laberintos dinÃ¡micos. Incluye un dashboard con GPS, ranking de eficiencia y telemetrÃ­a avanzada mediante Tailwind CSS y JavaScript.

ğŸ“¡ Swarm Analyzer Elite
Swarm Analyzer Elite es una plataforma de simulaciÃ³n interactiva basada en la web donde mÃºltiples agentes inteligentes (robots) compiten y colaboran para resolver laberintos generados proceduralmente. El proyecto utiliza Aprendizaje por Refuerzo (Q-Learning) para que los robots "aprendan" el camino Ã³ptimo hacia la meta.

ğŸš€ CaracterÃ­sticas Principales
IA con Q-Learning: Cada robot posee una tabla de memoria (Q-Table) que se actualiza en tiempo real, optimizando su toma de decisiones segÃºn las recompensas recibidas.

Sistema de Habilidades: Puedes desplegar agentes con diferentes especialidades que afectan su comportamiento:

âš¡ Velocidad: Se mueve el doble de rÃ¡pido por turno.

ğŸ‘ï¸ PercepciÃ³n: PenalizaciÃ³n reducida al chocar con paredes.

ğŸ—ºï¸ Explorador: Recibe bonificaciones altas por descubrir celdas nuevas.

ğŸ§  Memoria: Posee una tasa de aprendizaje (LearningRate) superior para adaptarse rÃ¡pido.

Dashboard en Tiempo Real: Monitoreo de posiciÃ³n GPS, logs de misiÃ³n y porcentaje de exploraciÃ³n del mapa.

Ranking de Eficiencia: ClasificaciÃ³n automÃ¡tica de los robots basada en su promedio de pasos para alcanzar el Ã©xito.

ğŸ› ï¸ TecnologÃ­as Utilizadas
HTML5 & CSS3: Estructura y diseÃ±o con animaciones personalizadas.

Tailwind CSS: Framework de utilidades para un diseÃ±o moderno y responsivo.

JavaScript (Vanilla): LÃ³gica del motor de simulaciÃ³n, algoritmos de IA y manipulaciÃ³n del DOM.

Google Fonts: TipografÃ­a "Quicksand" para una interfaz amigable.

ğŸ•¹ï¸ Instrucciones de Uso
ConfiguraciÃ³n del Agente: Selecciona una habilidad en el menÃº "Centro de Mando".

Despliegue: Haz clic en "Desplegar Agente" para aÃ±adir un robot al punto de inicio (esquina superior izquierda).

EjecuciÃ³n: Pulsa "Iniciar" para ver a los robots explorar.

OptimizaciÃ³n: Ajusta el "Velocidad del Motor" para acelerar la simulaciÃ³n o crea un "Nuevo Mapa" para poner a prueba la adaptabilidad de la IA.

ğŸ§  LÃ³gica de la IA (Q-Learning)
El aprendizaje se basa en la ecuaciÃ³n de Bellman simplificada, donde el valor de una acciÃ³n en un estado (s,a) se actualiza de la siguiente manera:

Q(s,a)â†Q(s,a)+Î±[r+Î³maxQ(s 
â€²
 ,a 
â€²
 )âˆ’Q(s,a)]
ExploraciÃ³n vs. ExplotaciÃ³n: Los robots usan una estrategia Epsilon-Greedy (Ïµ=0.15) para decidir si explorar rutas nuevas o usar el conocimiento ya adquirido.

Recompensas: Los agentes reciben +100 al llegar a la meta (ğŸ†) y penalizaciones pequeÃ±as por cada paso o choque.

ğŸ“‚ Estructura del CÃ³digo
class Robot: Define las propiedades fÃ­sicas, la lÃ³gica de movimiento y el cerebro de aprendizaje de cada agente.

initMaze(): Genera laberintos aleatorios asegurando que la meta sea alcanzable.

gameLoop(): El motor que coordina los turnos de todos los robots activos.

Â¿Te gustarÃ­a que aÃ±ada una secciÃ³n sobre cÃ³mo personalizar las recompensas de la IA o cÃ³mo instalarlo localmente?

